{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1 \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     height  vis  cloud  w_d  w_s  temp  dew   pres  storm\n",
      "date                                                                      \n",
      "2017-11-02 00:00:00       4   97      8   25    4   1.7  0.3  989.6      0\n",
      "2017-11-02 03:00:00       4   97      8   25    4   3.0  2.2  988.3      0\n",
      "2017-11-02 06:00:00       4   96      8   25    6   4.2  3.5  987.8      1\n",
      "2017-11-02 09:00:00       4   97      8   25    8   6.3  4.2  986.9      0\n",
      "2017-11-02 12:00:00       4   96      8   27    6   6.2  4.6  986.6      0\n"
     ]
    }
   ],
   "source": [
    "# step 2 load data\n",
    "weather = pd.read_csv('weather_donetsk.csv', sep=',', header=0, index_col=0, parse_dates=True, squeeze=True)\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8816, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7053 samples for training and 1763 for validation\n"
     ]
    }
   ],
   "source": [
    "# step 3 training - validation split\n",
    "val_weather = weather.sample(frac=0.2, random_state=1337)\n",
    "train_weather = weather.drop(val_weather.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_weather), len(val_weather))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 transform to dataset\n",
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"storm\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_weather)\n",
    "val_ds = dataframe_to_dataset(val_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'temp': <tf.Tensor: shape=(), dtype=float64, numpy=15.6>, 'w_s': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'height': <tf.Tensor: shape=(), dtype=int64, numpy=9>, 'pres': <tf.Tensor: shape=(), dtype=float64, numpy=988.7>, 'vis': <tf.Tensor: shape=(), dtype=int64, numpy=97>, 'cloud': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'w_d': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'dew': <tf.Tensor: shape=(), dtype=float64, numpy=-0.5>}\n",
      "Target: tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 to batch\n",
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 6 metods for prepare data\n",
    "# from category_encoders import *\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "# from tensorflow.keras.layers.experimental.preprocessing \n",
    "# from sklearn.preprocessing import CategoryEncoding\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import CategoryEncoding\n",
    "# from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "\n",
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature\n",
    "\n",
    "\n",
    "# def encode_string_categorical_feature(feature, name, dataset):\n",
    "#     # Create a StringLookup layer which will turn strings into integer indices\n",
    "#     index = StringLookup()\n",
    "\n",
    "#     # Prepare a Dataset that only yields our feature\n",
    "#     feature_ds = dataset.map(lambda x, y: x[name])\n",
    "#     feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "#     # Learn the set of possible string values and assign them a fixed integer index\n",
    "#     index.adapt(feature_ds)\n",
    "\n",
    "#     # Turn the string input into integer indices\n",
    "#     encoded_feature = index(feature)\n",
    "\n",
    "#     # Create a CategoryEncoding for our integer indices\n",
    "#     encoder = CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "#     # Prepare a dataset of indices\n",
    "#     feature_ds = feature_ds.map(index)\n",
    "\n",
    "#     # Learn the space of possible indices\n",
    "#     encoder.adapt(feature_ds)\n",
    "\n",
    "#     # Apply one-hot encoding to our indices\n",
    "#     encoded_feature = encoder(encoded_feature)\n",
    "#     return encoded_feature\n",
    "\n",
    "\n",
    "def encode_integer_categorical_feature(feature, name, dataset):\n",
    "    # Create a CategoryEncoding for our integer indices\n",
    "#     encoder = sklearn.preprocessing.CategoryEncoding(output_mode=\"binary\")\n",
    "    encoder = tensorflow.keras.layers.experimental.preprocessing.CategoryEncoding(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the space of possible indices\n",
    "    encoder.adapt(feature_ds)\n",
    "\n",
    "    # Apply one-hot encoding to our indices\n",
    "    encoded_feature = encoder(feature)\n",
    "    return encoded_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 7 prepare data and model\n",
    "\n",
    "height = keras.Input(shape=(1,), name=\"height\", dtype=\"int64\")\n",
    "vis = keras.Input(shape=(1,), name=\"vis\", dtype=\"int64\")\n",
    "cloud = keras.Input(shape=(1,), name=\"cloud\", dtype=\"int64\")\n",
    "w_d = keras.Input(shape=(1,), name=\"w_d\", dtype=\"int64\")\n",
    "\n",
    "# Numerical features\n",
    "w_s = keras.Input(shape=(1,), name=\"w_s\")\n",
    "temp = keras.Input(shape=(1,), name=\"temp\")\n",
    "dew = keras.Input(shape=(1,), name=\"dew\")\n",
    "pres = keras.Input(shape=(1,), name=\"pres\")\n",
    "\n",
    "all_inputs = [\n",
    "    height,\n",
    "    vis,\n",
    "    cloud,\n",
    "    w_d,\n",
    "    w_s,\n",
    "    temp,\n",
    "    dew,\n",
    "    pres,\n",
    "]\n",
    "\n",
    "# Integer categorical features\n",
    "height_encoded = encode_integer_categorical_feature(height, \"height\", train_ds)\n",
    "vis_encoded = encode_integer_categorical_feature(vis, \"vis\", train_ds)\n",
    "cloud_encoded = encode_integer_categorical_feature(cloud, \"cloud\", train_ds)\n",
    "w_d_encoded = encode_integer_categorical_feature(w_d, \"w_d\", train_ds)\n",
    "\n",
    "# String categorical features\n",
    "# thal_encoded = encode_string_categorical_feature(thal, \"thal\", train_ds)\n",
    "\n",
    "# Numerical features\n",
    "w_s_encoded = encode_numerical_feature(w_s, \"w_s\", train_ds)\n",
    "temp_encoded = encode_numerical_feature(temp, \"temp\", train_ds)\n",
    "dew_encoded = encode_numerical_feature(dew, \"dew\", train_ds)\n",
    "pres_encoded = encode_numerical_feature(pres, \"pres\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        height_encoded,\n",
    "        vis_encoded,\n",
    "        cloud_encoded,\n",
    "        w_d_encoded,\n",
    "        w_s_encoded,\n",
    "        temp_encoded,\n",
    "        dew_encoded,\n",
    "        pres_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(256, activation=\"relu\")(all_features)\n",
    "# x = layers.Dense(128, activation=\"relu\")(x)\n",
    "# x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "# x = layers.Dropout(0.5)(x)\n",
    "# x = layers.Dense(256, activation=\"relu\")(x),\n",
    "# x = layers.Dropout(0.3)(x),\n",
    "output = layers.Dense(8, activation=\"softmax\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip\n",
    "def create_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a deep neural net.\"\"\"\n",
    "  \n",
    "  # All models in this course are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # The features are stored in a two-dimensional 28X28 array. \n",
    "  # Flatten that two-dimensional array into a a one-dimensional \n",
    "  # 784-element array.\n",
    "  model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Define the first hidden layer.   \n",
    "  model.add(tf.keras.layers.Dense(units=32, activation='relu'))\n",
    "  \n",
    "  # Define a dropout regularization layer. \n",
    "  model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "\n",
    "  # Define the output layer. The units parameter is set to 10 because\n",
    "  # the model must choose among 10 possible output values (representing\n",
    "  # the digits from 0 to 9, inclusive).\n",
    "  #\n",
    "  # Don't change this layer.\n",
    "  model.add(tf.keras.layers.Dense(units=10, activation='softmax'))     \n",
    "                           \n",
    "  # Construct the layers into a model that TensorFlow can execute.  \n",
    "  # Notice that the loss function for multi-class classification\n",
    "  # is different than the loss function for binary classification.  \n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return model    \n",
    "\n",
    "\n",
    "def train_model(model, train_features, train_label, epochs,\n",
    "                batch_size=None, validation_split=0.1):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  history = model.fit(x=train_features, y=train_label, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True, \n",
    "                      validation_split=validation_split)\n",
    " \n",
    "  # To track the progression of training, gather a snapshot\n",
    "  # of the model's metrics at each epoch. \n",
    "  epochs = history.epoch\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  return epochs, hist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train_normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c2c743020313>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Train the model on the normalized training set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m epochs, hist = train_model(my_model, x_train_normalized, y_train, \n\u001b[0m\u001b[1;32m     12\u001b[0m                            epochs, batch_size, validation_split)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train_normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# skip\n",
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 50\n",
    "batch_size = 4000\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate)\n",
    "\n",
    "# Train the model on the normalized training set.\n",
    "epochs, hist = train_model(my_model, x_train_normalized, y_train, \n",
    "                           epochs, batch_size, validation_split)\n",
    "\n",
    "# Plot a graph of the metric vs. epochs.\n",
    "list_of_metrics_to_plot = ['accuracy']\n",
    "plot_curve(epochs, hist, list_of_metrics_to_plot)\n",
    "\n",
    "# Evaluate against the test set.\n",
    "print(\"\\n Evaluate the new model against the test set:\")\n",
    "my_model.evaluate(x=x_test_normalized, y=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "height (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "vis (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cloud (InputLayer)              [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "w_d (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "w_s (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "temp (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dew (InputLayer)                [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "pres (InputLayer)               [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding (CategoryEnco (None, 10)           1           height[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_1 (CategoryEn (None, 98)           1           vis[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_2 (CategoryEn (None, 10)           1           cloud[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "category_encoding_3 (CategoryEn (None, 37)           1           w_d[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "normalization (Normalization)   (None, 1)            3           w_s[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "normalization_1 (Normalization) (None, 1)            3           temp[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "normalization_2 (Normalization) (None, 1)            3           dew[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "normalization_3 (Normalization) (None, 1)            3           pres[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 159)          0           category_encoding[0][0]          \n",
      "                                                                 category_encoding_1[0][0]        \n",
      "                                                                 category_encoding_2[0][0]        \n",
      "                                                                 category_encoding_3[0][0]        \n",
      "                                                                 normalization[0][0]              \n",
      "                                                                 normalization_1[0][0]            \n",
      "                                                                 normalization_2[0][0]            \n",
      "                                                                 normalization_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          40960       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 8)            2056        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,032\n",
      "Trainable params: 43,016\n",
      "Non-trainable params: 16\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "# keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")\n",
    "model.summary()\n",
    "# my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.8956 - loss: 0.5183 - val_accuracy: 0.9019 - val_loss: 0.3913\n",
      "Epoch 2/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9108 - loss: 0.3523 - val_accuracy: 0.9019 - val_loss: 0.3681\n",
      "Epoch 3/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9111 - loss: 0.3384 - val_accuracy: 0.9019 - val_loss: 0.3642\n",
      "Epoch 4/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9108 - loss: 0.3287 - val_accuracy: 0.9019 - val_loss: 0.3505\n",
      "Epoch 5/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9107 - loss: 0.3268 - val_accuracy: 0.9019 - val_loss: 0.3501\n",
      "Epoch 6/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9115 - loss: 0.3187 - val_accuracy: 0.9019 - val_loss: 0.3524\n",
      "Epoch 7/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9117 - loss: 0.3141 - val_accuracy: 0.9013 - val_loss: 0.3489\n",
      "Epoch 8/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9112 - loss: 0.3117 - val_accuracy: 0.9013 - val_loss: 0.3571\n",
      "Epoch 9/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9117 - loss: 0.3086 - val_accuracy: 0.9013 - val_loss: 0.3499\n",
      "Epoch 10/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9115 - loss: 0.3064 - val_accuracy: 0.9013 - val_loss: 0.3513\n",
      "Epoch 11/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9114 - loss: 0.3039 - val_accuracy: 0.9013 - val_loss: 0.3499\n",
      "Epoch 12/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9112 - loss: 0.3025 - val_accuracy: 0.9019 - val_loss: 0.3471\n",
      "Epoch 13/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9111 - loss: 0.2993 - val_accuracy: 0.9013 - val_loss: 0.3496\n",
      "Epoch 14/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9112 - loss: 0.2971 - val_accuracy: 0.9007 - val_loss: 0.3501\n",
      "Epoch 15/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9110 - loss: 0.2907 - val_accuracy: 0.9007 - val_loss: 0.3497\n",
      "Epoch 16/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9114 - loss: 0.2893 - val_accuracy: 0.9019 - val_loss: 0.3526\n",
      "Epoch 17/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9121 - loss: 0.2892 - val_accuracy: 0.9007 - val_loss: 0.3480\n",
      "Epoch 18/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9139 - loss: 0.2856 - val_accuracy: 0.9013 - val_loss: 0.3616\n",
      "Epoch 19/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9122 - loss: 0.2838 - val_accuracy: 0.9007 - val_loss: 0.3494\n",
      "Epoch 20/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9127 - loss: 0.2827 - val_accuracy: 0.8985 - val_loss: 0.3524\n",
      "Epoch 21/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9115 - loss: 0.2800 - val_accuracy: 0.9007 - val_loss: 0.3603\n",
      "Epoch 22/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9139 - loss: 0.2785 - val_accuracy: 0.9002 - val_loss: 0.3675\n",
      "Epoch 23/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9121 - loss: 0.2777 - val_accuracy: 0.9007 - val_loss: 0.3571\n",
      "Epoch 24/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9125 - loss: 0.2776 - val_accuracy: 0.8985 - val_loss: 0.3540\n",
      "Epoch 25/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9138 - loss: 0.2739 - val_accuracy: 0.9002 - val_loss: 0.3659\n",
      "Epoch 26/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9135 - loss: 0.2701 - val_accuracy: 0.8996 - val_loss: 0.3555\n",
      "Epoch 27/50\n",
      "221/221 [==============================] - 1s 7ms/step - accuracy: 0.9139 - loss: 0.2692 - val_accuracy: 0.9007 - val_loss: 0.3645\n",
      "Epoch 28/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9152 - loss: 0.2683 - val_accuracy: 0.8990 - val_loss: 0.3622\n",
      "Epoch 29/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9146 - loss: 0.2633 - val_accuracy: 0.9007 - val_loss: 0.3644\n",
      "Epoch 30/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9139 - loss: 0.2624 - val_accuracy: 0.9019 - val_loss: 0.3635\n",
      "Epoch 31/50\n",
      "221/221 [==============================] - 1s 7ms/step - accuracy: 0.9155 - loss: 0.2612 - val_accuracy: 0.9002 - val_loss: 0.3672\n",
      "Epoch 32/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9141 - loss: 0.2617 - val_accuracy: 0.9007 - val_loss: 0.3714\n",
      "Epoch 33/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9161 - loss: 0.2582 - val_accuracy: 0.9002 - val_loss: 0.3774\n",
      "Epoch 34/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9176 - loss: 0.2572 - val_accuracy: 0.8996 - val_loss: 0.3716\n",
      "Epoch 35/50\n",
      "221/221 [==============================] - 1s 6ms/step - accuracy: 0.9152 - loss: 0.2561 - val_accuracy: 0.8996 - val_loss: 0.3657\n",
      "Epoch 36/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9142 - loss: 0.2546 - val_accuracy: 0.9002 - val_loss: 0.3656\n",
      "Epoch 37/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9172 - loss: 0.2501 - val_accuracy: 0.8990 - val_loss: 0.3685\n",
      "Epoch 38/50\n",
      "221/221 [==============================] - 1s 4ms/step - accuracy: 0.9149 - loss: 0.2491 - val_accuracy: 0.8985 - val_loss: 0.3750\n",
      "Epoch 39/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9158 - loss: 0.2495 - val_accuracy: 0.8968 - val_loss: 0.3703\n",
      "Epoch 40/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9151 - loss: 0.2449 - val_accuracy: 0.9002 - val_loss: 0.3784\n",
      "Epoch 41/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9168 - loss: 0.2434 - val_accuracy: 0.9019 - val_loss: 0.3802\n",
      "Epoch 42/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9176 - loss: 0.2479 - val_accuracy: 0.8990 - val_loss: 0.3711\n",
      "Epoch 43/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9145 - loss: 0.2432 - val_accuracy: 0.8968 - val_loss: 0.3735\n",
      "Epoch 44/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9144 - loss: 0.2459 - val_accuracy: 0.8962 - val_loss: 0.3799\n",
      "Epoch 45/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9168 - loss: 0.2415 - val_accuracy: 0.8985 - val_loss: 0.3792\n",
      "Epoch 46/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9154 - loss: 0.2409 - val_accuracy: 0.8968 - val_loss: 0.3735\n",
      "Epoch 47/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9182 - loss: 0.2391 - val_accuracy: 0.8979 - val_loss: 0.3833\n",
      "Epoch 48/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9193 - loss: 0.2385 - val_accuracy: 0.8996 - val_loss: 0.3779\n",
      "Epoch 49/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9152 - loss: 0.2382 - val_accuracy: 0.9007 - val_loss: 0.3884\n",
      "Epoch 50/50\n",
      "221/221 [==============================] - 1s 5ms/step - accuracy: 0.9188 - loss: 0.2356 - val_accuracy: 0.8973 - val_loss: 0.3808\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3d143b0d68>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 8 fit model\n",
    "model.fit(train_ds, epochs=50, validation_data=val_ds)\n",
    "# my_model.fit(train_ds, epochs=50, validation_data=val_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slavam/my_python/my_python_env/lib/python3.5/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/slavam/my_python/my_python_env/lib/python3.5/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: multistorm_donetsk_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('multistorm_donetsk_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 9 input and prepare data, prediction\n",
    "# ЩЭСИД 34519 42997 00502 10344 20157 39832 40054 58003 555 1/059=\n",
    "# ЩЭСМЮ 34519 12997 63406 10098 21009 39892 40136 52022 69902 80002 333 20086 555 10015=\n",
    "sample = {\n",
    "    \"height\": 9,\n",
    "    \"vis\": 97,\n",
    "    \"cloud\": 0,\n",
    "    \"w_d\": 5,\n",
    "    \"w_s\": 2,\n",
    "    \"temp\": 34.4,\n",
    "    \"dew\": 15.7,\n",
    "    \"pres\": 983.2\n",
    "}\n",
    "# multistorm_model = tf.keras.models.load_model('multistorm_donetsk_model')\n",
    "input_dict = {name: tf.convert_to_tensor([value]) for name, value in sample.items()}\n",
    "# predictions = multistorm_model.predict(input_dict)\n",
    "# model = tf.keras.models.load_model('multistorm_donetsk_model')\n",
    "predictions = model.predict(input_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 10 show\n",
    "import matplotlib.pyplot as plt\n",
    "# predictions\n",
    "plt.plot(np.squeeze(predictions))\n",
    "plt.ylabel('Вероятность')\n",
    "plt.xlabel('Тип опасного/стихийного явления')\n",
    "# plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 8 artists>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step 11 show 2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "storm = ('Без шторма', 'Ветер', 'Низкая облачность', 'Видимость', 'Гололед', 'Налипание мокрого снега', 'Гроза', 'Прочее')\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(storm, np.squeeze(predictions))\n",
    "\n",
    "# predictions.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
