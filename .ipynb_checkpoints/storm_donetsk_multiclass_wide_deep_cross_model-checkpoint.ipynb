{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 09:15:04.788244: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = pd.read_csv('donetsk_17_21_with_storms.csv', sep=';', header=0, parse_dates=True, squeeze=True)\n",
    "code = weather.pop('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['wind_direction'] = weather['wind_direction']*10\n",
    "wv = weather.pop('wind_speed')\n",
    "\n",
    "# Convert to radians.\n",
    "wd_rad = weather.pop('wind_direction')*np.pi / 180\n",
    "\n",
    "# Calculate the wind x and y components.\n",
    "weather['w_x'] = wv*np.cos(wd_rad)\n",
    "weather['w_y'] = wv*np.sin(wd_rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_time = pd.to_datetime(weather.pop('started_at'), format='%Y-%m-%d %H:%M:%S')\n",
    "timestamp_s = date_time.map(pd.Timestamp.timestamp)\n",
    "day = 24*60*60\n",
    "year = (365.2425)*day\n",
    "\n",
    "weather['day_sin'] = np.sin(timestamp_s * (2 * np.pi / day))\n",
    "weather['day_cos'] = np.cos(timestamp_s * (2 * np.pi / day))\n",
    "weather['year_sin'] = np.sin(timestamp_s * (2 * np.pi / year))\n",
    "weather['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cloud_height</th>\n",
       "      <th>cloud_amount</th>\n",
       "      <th>temperature</th>\n",
       "      <th>temperature_dew</th>\n",
       "      <th>pressure</th>\n",
       "      <th>pressure_tendency</th>\n",
       "      <th>pressure_tendency_value</th>\n",
       "      <th>w_x</th>\n",
       "      <th>w_y</th>\n",
       "      <th>day_sin</th>\n",
       "      <th>day_cos</th>\n",
       "      <th>year_sin</th>\n",
       "      <th>year_cos</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>989.4</td>\n",
       "      <td>7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.942611e-12</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-0.866949</td>\n",
       "      <td>-0.498398</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>989.3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.868018</td>\n",
       "      <td>-0.496532</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>15.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>989.7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.505955e-12</td>\n",
       "      <td>-0.869084</td>\n",
       "      <td>-0.494665</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>17.7</td>\n",
       "      <td>13.2</td>\n",
       "      <td>988.9</td>\n",
       "      <td>8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-0.684040</td>\n",
       "      <td>-1.879385</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.870146</td>\n",
       "      <td>-0.492795</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>989.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-1.368081</td>\n",
       "      <td>-3.758770</td>\n",
       "      <td>8.069299e-12</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-0.871203</td>\n",
       "      <td>-0.490922</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cloud_height  cloud_amount  temperature  temperature_dew  pressure  \\\n",
       "0             5             8         14.4             13.5     989.4   \n",
       "1             5             8         14.2             13.4     989.3   \n",
       "2             5             8         15.2             13.2     989.7   \n",
       "3             5             6         17.7             13.2     988.9   \n",
       "4             5             7         16.5             13.4     989.1   \n",
       "\n",
       "   pressure_tendency  pressure_tendency_value       w_x       w_y  \\\n",
       "0                  7                      1.3  0.000000  0.000000   \n",
       "1                  7                      0.1  0.000000  0.000000   \n",
       "2                  3                      0.4  0.000000  0.000000   \n",
       "3                  8                      0.8 -0.684040 -1.879385   \n",
       "4                  3                      0.2 -1.368081 -3.758770   \n",
       "\n",
       "        day_sin       day_cos  year_sin  year_cos  code  \n",
       "0 -2.942611e-12  1.000000e+00 -0.866949 -0.498398     0  \n",
       "1  7.071068e-01  7.071068e-01 -0.868018 -0.496532     0  \n",
       "2  1.000000e+00  5.505955e-12 -0.869084 -0.494665     0  \n",
       "3  7.071068e-01 -7.071068e-01 -0.870146 -0.492795     8  \n",
       "4  8.069299e-12 -1.000000e+00 -0.871203 -0.490922     8  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather['code'] = code\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size:  9189\n",
      "Test split size:  2171\n"
     ]
    }
   ],
   "source": [
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for _, group_data in weather.groupby(\"code\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.8\n",
    "    train_splits.append(group_data[random_selection])\n",
    "    test_splits.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_splits).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.concat(test_splits).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(\"Train split size: \", len(train_data.index))\n",
    "print(\"Test split size: \", len(test_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False)\n",
    "test_data.to_csv(test_data_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_HEADER = [\n",
    "    \"cloud_height\",\n",
    "    \"cloud_amount\",\n",
    "    \"temperature\",\n",
    "    \"temperature_dew\",\n",
    "    \"pressure\",\n",
    "    \"pressure_tendency\",\n",
    "    \"pressure_tendency_value\",\n",
    "    \"w_x\",\n",
    "    \"w_y\",\n",
    "    \"day_sin\",\n",
    "    \"day_cos\",\n",
    "    \"year_sin\",\n",
    "    \"year_cos\",\n",
    "    \"code\",\n",
    "]\n",
    "TARGET_FEATURE_NAME = \"code\"\n",
    "\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"cloud_height\",\n",
    "    \"cloud_amount\",\n",
    "    \"temperature\",\n",
    "    \"temperature_dew\",\n",
    "    \"pressure\",\n",
    "    \"pressure_tendency\",\n",
    "    \"pressure_tendency_value\",\n",
    "    \"w_x\",\n",
    "    \"w_y\",\n",
    "    \"day_sin\",\n",
    "    \"day_cos\",\n",
    "    \"year_sin\",\n",
    "    \"year_cos\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "#     \"cloud_height\": list(visibility[\"cloud_height\"].unique()),\n",
    "#     \"cloud_amount\": list(visibility[\"cloud_amount\"].unique()),\n",
    "#     \"pressure_tendency\": list(visibility[\"pressure_tendency\"].unique())\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0.0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        select_columns=[\n",
    "            \"cloud_height\",\n",
    "            \"cloud_amount\",\n",
    "            \"temperature\",\n",
    "            \"temperature_dew\",\n",
    "            \"pressure\",\n",
    "            \"pressure_tendency\",\n",
    "            \"pressure_tendency_value\",\n",
    "            \"w_x\",\n",
    "            \"w_y\",\n",
    "            \"day_sin\",\n",
    "            \"day_cos\",\n",
    "            \"year_sin\",\n",
    "            \"year_cos\",\n",
    "            \"code\",\n",
    "        ],\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name='code', #TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CacheDataset shapes: (OrderedDict([(cloud_height, (None,)), (cloud_amount, (None,)), (temperature, (None,)), (temperature_dew, (None,)), (pressure, (None,)), (pressure_tendency, (None,)), (pressure_tendency_value, (None,)), (w_x, (None,)), (w_y, (None,)), (day_sin, (None,)), (day_cos, (None,)), (year_sin, (None,)), (year_cos, (None,))]), (None,)), types: (OrderedDict([(cloud_height, tf.float32), (cloud_amount, tf.float32), (temperature, tf.float32), (temperature_dew, tf.float32), (pressure, tf.float32), (pressure_tendency, tf.float32), (pressure_tendency_value, tf.float32), (w_x, tf.float32), (w_y, tf.float32), (day_sin, tf.float32), (day_cos, tf.float32), (year_sin, tf.float32), (year_cos, tf.float32)]), tf.float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(\"Test accuracy: \", round(accuracy * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "def encode_inputs(inputs, use_embedding=False):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "#         if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "#             vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "#             # Create a lookup to convert string values to an integer indices.\n",
    "#             # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "#             # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "#             lookup = StringLookup(\n",
    "#                 vocabulary=vocabulary,\n",
    "#                 mask_token=None,\n",
    "#                 num_oov_indices=0,\n",
    "#                 output_mode=\"int\" if use_embedding else \"binary\",\n",
    "#             )\n",
    "#             if use_embedding:\n",
    "#                 # Convert the string input values into integer indices.\n",
    "#                 encoded_feature = lookup(inputs[feature_name])\n",
    "#                 embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "#                 # Create an embedding layer with the specified dimensions.\n",
    "#                 embedding = layers.Embedding(\n",
    "#                     input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "#                 )\n",
    "#                 # Convert the index values to embedding representations.\n",
    "#                 encoded_feature = embedding(encoded_feature)\n",
    "#             else:\n",
    "#                 # Convert the string input values into a one hot encoding.\n",
    "#                 encoded_feature = lookup(tf.expand_dims(inputs[feature_name], -1))\n",
    "#         else:\n",
    "            # Use the numerical features as-is.\n",
    "        encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "35/35 [==============================] - 0s 9ms/step - sparse_categorical_accuracy: 0.2285 - loss: 2.1627\n",
      "Epoch 2/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.6461 - loss: 1.3435\n",
      "Epoch 3/50\n",
      "35/35 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.8804 - loss: 0.8713\n",
      "Epoch 4/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9031 - loss: 0.6403\n",
      "Epoch 5/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9050 - loss: 0.5400\n",
      "Epoch 6/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.4875\n",
      "Epoch 7/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9050 - loss: 0.4602\n",
      "Epoch 8/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.4422\n",
      "Epoch 9/50\n",
      "35/35 [==============================] - 0s 4ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.4332\n",
      "Epoch 10/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9051 - loss: 0.4213\n",
      "Epoch 11/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.4146\n",
      "Epoch 12/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9053 - loss: 0.4101\n",
      "Epoch 13/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.3989\n",
      "Epoch 14/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9046 - loss: 0.3998\n",
      "Epoch 15/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9049 - loss: 0.3932\n",
      "Epoch 16/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.3883\n",
      "Epoch 17/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9047 - loss: 0.3881\n",
      "Epoch 18/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9045 - loss: 0.3823\n",
      "Epoch 19/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9046 - loss: 0.3804\n",
      "Epoch 20/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9047 - loss: 0.3784\n",
      "Epoch 21/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9047 - loss: 0.3753\n",
      "Epoch 22/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9048 - loss: 0.3735\n",
      "Epoch 23/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9043 - loss: 0.3728\n",
      "Epoch 24/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9048 - loss: 0.3700\n",
      "Epoch 25/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9047 - loss: 0.3674\n",
      "Epoch 26/50\n",
      "35/35 [==============================] - 0s 8ms/step - sparse_categorical_accuracy: 0.9051 - loss: 0.3640\n",
      "Epoch 27/50\n",
      "35/35 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.3666\n",
      "Epoch 28/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9056 - loss: 0.3609\n",
      "Epoch 29/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9046 - loss: 0.3634\n",
      "Epoch 30/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9048 - loss: 0.3644\n",
      "Epoch 31/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9050 - loss: 0.3577\n",
      "Epoch 32/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9049 - loss: 0.3566\n",
      "Epoch 33/50\n",
      "35/35 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9047 - loss: 0.3552\n",
      "Epoch 34/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9046 - loss: 0.3549\n",
      "Epoch 35/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9051 - loss: 0.3545\n",
      "Epoch 36/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9046 - loss: 0.3501\n",
      "Epoch 37/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9055 - loss: 0.3508\n",
      "Epoch 38/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9049 - loss: 0.3464\n",
      "Epoch 39/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9053 - loss: 0.3522\n",
      "Epoch 40/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9046 - loss: 0.3466\n",
      "Epoch 41/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.3489\n",
      "Epoch 42/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.3461\n",
      "Epoch 43/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9047 - loss: 0.3428\n",
      "Epoch 44/50\n",
      "35/35 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9048 - loss: 0.3440\n",
      "Epoch 45/50\n",
      "35/35 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9050 - loss: 0.3444\n",
      "Epoch 46/50\n",
      "35/35 [==============================] - 0s 7ms/step - sparse_categorical_accuracy: 0.9054 - loss: 0.3443\n",
      "Epoch 47/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9059 - loss: 0.3407\n",
      "Epoch 48/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9050 - loss: 0.3446\n",
      "Epoch 49/50\n",
      "35/35 [==============================] - 0s 5ms/step - sparse_categorical_accuracy: 0.9052 - loss: 0.3380\n",
      "Epoch 50/50\n",
      "35/35 [==============================] - 0s 6ms/step - sparse_categorical_accuracy: 0.9048 - loss: 0.3398\n",
      "Model training finished\n",
      "Test accuracy:  89.64\n"
     ]
    }
   ],
   "source": [
    "run_experiment(baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/slavam/my_python/my_python_env/lib/python3.5/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/slavam/my_python/my_python_env/lib/python3.5/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: multistorm_donetsk_baseline_wdc_model/assets\n"
     ]
    }
   ],
   "source": [
    "baseline_model.save('multistorm_donetsk_baseline_wdc_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_wide_and_deep_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs, use_embedding=True)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(wide_and_deep_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multistorm_donetsk_wide_deep_model/assets\n"
     ]
    }
   ],
   "source": [
    "wide_and_deep_model.save('multistorm_donetsk_wide_deep_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deep_and_cross_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    x0 = encode_inputs(inputs, use_embedding=True)\n",
    "\n",
    "    cross = x0\n",
    "    for _ in hidden_units:\n",
    "        units = cross.shape[-1]\n",
    "        x = layers.Dense(units)(cross)\n",
    "        cross = x0 * x + cross\n",
    "    cross = layers.BatchNormalization()(cross)\n",
    "\n",
    "    deep = x0\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([cross, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "deep_and_cross_model = create_deep_and_cross_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(deep_and_cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multistorm_donetsk_deep_cross_model/assets\n"
     ]
    }
   ],
   "source": [
    "deep_and_cross_model.save('multistorm_donetsk_deep_cross_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-11 09:15:35.939391: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-10-11 09:15:35.984190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-10-11 09:15:35.984893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GT 710 computeCapability: 3.5\n",
      "coreClock: 0.954GHz coreCount: 1 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 11.92GiB/s\n",
      "2021-10-11 09:15:35.984967: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-10-11 09:15:35.994693: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-10-11 09:15:35.994876: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-10-11 09:15:35.996729: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-10-11 09:15:35.997161: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-10-11 09:15:35.997848: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-10-11 09:15:35.999056: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-10-11 09:15:35.999303: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2021-10-11 09:15:35.999318: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2021-10-11 09:15:35.999734: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-11 09:15:35.999910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-10-11 09:15:35.999947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2021-10-11 09:15:38.042224: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-10-11 09:15:38.060183: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3893145000 Hz\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def prepare_data(date_term, telegram, model_name):\n",
    "    ret = {}\n",
    "    ret['cloud_height'] = int(telegram[14:15])\n",
    "    ret['cloud_amount'] = int(telegram[18:19])\n",
    "    ret['pressure_tendency'] = int(telegram[49:50])\n",
    "    sign = ''\n",
    "    if telegram[25:26] == '1':\n",
    "        sign = '-'\n",
    "    ret['temperature'] = float(sign+telegram[26:28]+'.'+telegram[28:29])\n",
    "    sign = ''\n",
    "    if telegram[31:32] == '1':\n",
    "        sign = '-'\n",
    "    ret['temperature_dew'] = float(sign+telegram[32:34]+'.'+telegram[34:35])\n",
    "    p1 = '1'\n",
    "    if telegram[37:38] != '0':\n",
    "        p1 = ''\n",
    "    ret['pressure'] = float(p1+telegram[37:40]+'.'+telegram[40:41])\n",
    "    ret['pressure_tendency_value'] = float(telegram[50:52]+'.'+telegram[52:53])\n",
    "    wv = float(telegram[21:23]+'.')\n",
    "    wd_rad = int(telegram[19:21])*10*np.pi/180\n",
    "    ret['w_x'] = wv*np.cos(wd_rad)\n",
    "    ret['w_y'] = wv*np.sin(wd_rad)\n",
    "    d = datetime.strptime(date_term, \"%Y-%m-%d %H:%M:%S\")\n",
    "    s = time.mktime(d.timetuple())\n",
    "    day = 24*60*60\n",
    "    year = (365.2425)*day\n",
    "    ret['day_sin'] = np.sin(s * (2 * np.pi / day))\n",
    "    ret['day_cos'] = np.cos(s * (2 * np.pi / day))\n",
    "    ret['year_sin'] = np.sin(s * (2 * np.pi / year))\n",
    "    ret['year_cos'] = np.cos(s * (2 * np.pi / year))\n",
    "    input_dict = {name: tf.convert_to_tensor([value]) for name, value in ret.items()}\n",
    "    model = tf.keras.models.load_model(model_name)\n",
    "    predictions = model.predict(input_dict)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "d_t = '2021-10-11 06:00:00'\n",
    "telegram = 'ЩЭСМЮ 34519 32697 70902 10093 20013 30004 40251 57010 87500 333 20068 555 10010 30003 52003='\n",
    "predictions = prepare_data(d_t, telegram, 'multistorm_donetsk_deep_cross_model')\n",
    "#                            'multistorm_donetsk_baseline_wdc_model')\n",
    "#                            'multistorm_donetsk_wide_deep_model')\n",
    "#                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 9 artists>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "storm = ('Без шторма', 'Ветер', 'Низкая облачность', 'Видимость', 'Гололед', 'Сложные отложения', 'Налипание мокрого снега', 'Град', 'Гроза')\n",
    "fig, ax = plt.subplots()\n",
    "ax.barh(storm, np.squeeze(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1318750e-01, 7.4757315e-02, 7.0336275e-05, 8.5953949e-03,\n",
       "        5.8539154e-05, 2.8952809e-06, 3.9993134e-05, 3.6103160e-05,\n",
       "        3.2519891e-03]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
